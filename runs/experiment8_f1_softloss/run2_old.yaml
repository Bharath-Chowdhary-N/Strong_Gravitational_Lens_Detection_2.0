# settings.yaml file
# This file contains all settings for a model to run.

# Model Name
model_name: "resnet18_macro_double_soft_f1"    # String

# Loading the input data
fraction_to_load_sources_train  : 1.0     #float # range = [0,1]  train
fraction_to_load_negatives_train: 1.0     #float # range = [0,1]  train
fraction_to_load_lenses_train   : 1.0     #float # range = [0,1]  train

fraction_to_load_sources_vali  : 1.0     #float # range = [0,1]   validation
fraction_to_load_negatives_vali: 1.0     #float # range = [0,1]   validation
fraction_to_load_lenses_vali   : 1.0     #float # range = [0,1]   validation

# Whether to normalize (normalize per data array and not per image) the data during the image loading process.s
normalize: "per_image"        #options = {"None", "per_image", "per_array", "adapt_hist_eq"}

# Chunk Parameters
num_chunks: 12000                      #int # Number of chunks to be generated 
chunksize : 1024                      #int # The number of images that will fit into one chunk

# Storing results parameters.
chunk_plot_interval: 100               #int # Determines at which training interval a plot of the loss and binary accuracy is generated and stored to a file.
chunk_save_interval: 50               #int # After this amount of chunks the model will be saved.

# Validation Params
validation_chunksize: 128

## EXPERIMENT PARAMETERS
use_avg_pooling_2D: True            #boolean, # Whether the resnet contains GLOBAL AVG POOLING

# Network Paramters
net_name         : "resnet18"               #string# Determines which model will be loaded options={"resnet18"}
net_learning_rate: 0.0001                   #float#
net_model_metrics: "macro_f1"               #string# Options {"binary_accuracy", "macro_f1"}
net_loss_function: "macro_double_soft_f1"   #string # Which loss function should be used during training? Options {"binary_crossentropy", "macro_soft_f1", "macro_double_soft_f1"}
net_num_outputs  : 1                        #int# How many output neurons does the network need?
net_epochs       : 1                        #int# How many epochs are done. Set to 1, because we generate infinite data. Therefore you should look at the parameter num_chunks.
net_batch_size   : 32                       #int#

##### Paths to data
lenses_path_train   : "data/train/lenses/"
negatives_path_train: "data/train/negatives/"
sources_path_train  : "data/train/sources/"

lenses_path_validation   : "data/validation/lenses/"
negatives_path_validation: "data/validation/negatives/"
sources_path_validation  : "data/validation/sources/"

root_dir_models: models         # string

# Data type of images in the numpy array
data_type: "np.float32"

# Image dimensionality
img_width: 101
img_height: 101
img_channels: 1

# Determines the splitting point of the data. Splitting percentage between test and train data.
#test_fraction: 0.2             # 0.2 means that 20% of the data will be reserved for test data.
# The data fractions in this project is 80% training, 10% validation and 10% test. This has been chosen at a folder level.

# Alpha scaling, randomly drawn from this uniform distribution. Because the lensing features usually are of a lower luminosity than the LRG. Source scaling factor.
mock_lens_alpha_scaling_min: 0.02     #float
mock_lens_alpha_scaling_max: 0.30     #float

# Whether you want to see plots and extra print output
verbatim: False

# Augmenation Parameters:
aug_zoom_range_min: 1.0             #float# This range will be sampled from uniformly.
aug_zoom_range_max: 1.05            #float# This range will be sampled from uniformly.
aug_num_pixels_shift_allowed: 4     #int# In Pixels
aug_rotation_range    : 360         #int# In Degrees
aug_do_horizontal_flip: True        #boolean# 50% of the time do a horizontal flip)  
aug_default_fill_mode : 'nearest'   #string# Interpolation method, for data augmentation.
